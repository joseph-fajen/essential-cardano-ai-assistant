{
  "url": "https://developers.cardano.org/docs/operate-a-stake-pool/grafana-dashboard-tutorial",
  "content": "![Cardano Logo](/img/cardano-black.svg)\n![Cardano Logo](/img/cardano-white.svg)\n\n# Grafana Dashboard Tutorial\n\n![Grafana Tutorial](/assets/images/snsky_dashboard-711ff4dc902654c377900fa0269c6848.jpg)\n\n![Grafana Tutorial](/assets/images/snsky_dashboard-711ff4dc902654c377900fa0269c6848.jpg)\n\nOnce your Cardano pool is successfully set up, then comes the most beautiful part - setting up your Dashboard and Alerts!\n\nThis documentation brings some of the available information in greater detail and will hopefully help Stake Pool Operators manage their pools more efficiently. This tutorial is for education and learning purposes only!\n\n**Prerequisites:**\n\n## 1. Install prometheus node exporter[​](#1-install-prometheus-node-exporter \"Direct link to 1. Install prometheus node exporter\")\n\nFirst, install Prometheus node exporter on the Block Producing and all Relay Nodes:\n\n`$ sudo apt-get install -y prometheus-node-exporter  \n  \n$ sudo systemctl enable prometheus-node-exporter.service`\n\nFor Ubuntu 18.04 refer to the following tutorial: [Ubuntu 18.04 Tutorial](https://sanskys.github.io/grafana/)\n\nUpdate `mainnet-config.json` config files with new hasEKG and has Prometheus ports:\n\n`mainnet-config.json`\n`$ cd $NODE_HOME  \n$ sed -i config.json -e \"s/127.0.0.1/0.0.0.0/g\"  \n  \nOn Producer Node open ports 12798 and 9100  \n  \n$ sudo ufw allow proto tcp from <Monitoring Node IP address> to any port 9100  \n  \n$ sudo ufw allow proto tcp from <Monitoring Node IP address> to any port 12798  \n  \n$ sudo ufw reload`\n\nRestart the nodes:\n\n`$ sudo systemctl restart <your node name e.g. cardano-testnode>`\n\n## 2. Install Prometheus on the Monitoring Node[​](#2-install-prometheus-on-the-monitoring-node \"Direct link to 2. Install Prometheus on the Monitoring Node\")\n\nInstall Prometheus on the Monitoring Node - the Node where the Grafana Server will run. This could be one of the Relay nodes or a separate dedicated node for monitoring.\n\n`$ sudo apt-get install -y prometheus`\n\n## 3. Install Grafana on Monitoring Node[​](#3-install-grafana-on-monitoring-node \"Direct link to 3. Install Grafana on Monitoring Node\")\n\n`$ wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -  \n  \n$ echo \"deb https://packages.grafana.com/oss/deb stable main\" > grafana.list  \n$ sudo mv grafana.list /etc/apt/sources.list.d/grafana.list  \n  \n$ sudo apt-get update && sudo apt-get install -y grafana`\n\nEnable services so they start automatically:\n\n`$ sudo systemctl enable grafana-server.service  \n$ sudo systemctl enable prometheus.service  \n$ sudo systemctl enable prometheus-node-exporter.service`\n\nUpdate `prometheus.yml` located in `/etc/prometheus/prometheus.yml`:\n\n`prometheus.yml`\n`/etc/prometheus/prometheus.yml`\n\nChange the *ip address* in the following command:\n\n`$ cat > prometheus.yml << EOF  \nglobal:  \n scrape_interval: 15s # By default, scrape targets every 15 seconds.  \n  \n # Attach these labels to any time series or alerts when communicating with  \n # external systems (federation, remote storage, Alertmanager).  \n external_labels:  \n monitor: 'codelab-monitor'  \n  \n# A scrape configuration containing exactly one endpoint to scrape:  \n# Here it's Prometheus itself.  \nscrape_configs:  \n # The job name is added as a label job=<job_name> to any timeseries scraped from this config.  \n - job_name: 'prometheus'  \n  \n static_configs:  \n - targets: ['localhost:9100']  \n  \n labels:  \n alias: 'relaynode1'  \n type: 'cardano-node'  \n  \n - targets: ['<relay node 2 public ip address>:9100']  \n  \n labels:  \n alias: 'relaynode2'  \n type: 'cardano-node'  \n - targets: ['<block producer public ip address>:9100']  \n  \n labels:  \n alias: 'block-producer-node'  \n type: 'cardano-node'  \n - targets: ['localhost:12798']  \n labels:  \n alias: 'relaynode1'  \n type: 'cardano-node'  \n  \n - targets: ['<relay node 2 public ip address>:12798']  \n  \n labels:  \n alias: 'relaynode2'  \n type: 'cardano-node'  \n  \n - targets: ['<block producer public ip address>:12798']  \n labels:  \n alias: 'block-producer-node'  \n type: 'cardano-node'  \n  \nEOF`\n\nif you have more than two Relay Nodes, add all your Relays as new \"targets\" in the config above:\n\n`$ sudo mv prometheus.yml /etc/prometheus/prometheus.yml`\n\nRestart the services:\n\n`$ sudo systemctl restart grafana-server.service  \n$ sudo systemctl restart prometheus.service  \n$ sudo systemctl restart prometheus-node-exporter.service`\n\nVerify that the services are running properly:\n\n`$ sudo systemctl status grafana-server.service prometheus.service prometheus-node-exporter.service`\n\nOn the Monitoring Node, open port 3000 for Grafana:\n\n`$ sudo ufw allow from <your home IP address from where you plan to access Grafana> to any port 3000`\n\nPlease refer to [Grafana Labs Security](https://grafana.com/docs/grafana/latest/administration/security/) for hardening: e.g. by default the communication with the Grafana server is unencrypted.\n\n## 4. Setting up Grafana Dashboard[​](#4-setting-up-grafana-dashboard \"Direct link to 4. Setting up Grafana Dashboard\")\n\nOn Relay Node, open `http://localhost:3000` or `http://`*your Relay Node ip address*`:3000` in your local browser.\n\n`http://localhost:3000`\n`http://`\n`:3000`\n\nLogin with admin / admin\n\nChange password\n\n![Datasource](/assets/images/snsky_prometheus-9048448c210ab690edf45f82500421d4.jpg)\n\n![Datasource](/assets/images/snsky_prometheus-9048448c210ab690edf45f82500421d4.jpg)\n\nClick the configuration gear icon, then Add data Source\n\nSelect Prometheus\n\nSet Name to \"Prometheus\"\n\nSet URL to `http://localhost:9090`\n\n`http://localhost:9090`\n\nClick Save & Test\n\nDownload my Dashboard that you see on the top of this page, from the following GitHub link and save the JSON file\n\n[SNSKY Dashboard Example](https://github.com/sanskys/SNSKY/blob/main/SNSKY_Dashboard_v2.json)\n\nin Grafana, Click Create + icon (in left Menu) > Import\nAdd dashboard by Upload JSON file\nClick the Import button.\n\nIf you nodes are in several time zones, it is useful to add the Grafana Clock panel\n\n`$ grafana-cli plugins install grafana-clock-panel`\n\nInstalled panels are available immediately in the Dashboards section in your Grafana main menu.\n\nTo see a list of installed panels, click the Plugins item in the main menu. Both core panels and installed panels will appear.\n\n## 5. Add Data from Cexplorer to the Dashboard[​](#5-add-data-from-cexplorer-to-the-dashboard \"Direct link to 5. Add Data from Cexplorer to the Dashboard\")\n\nCexplorer provides API where we can collect data for our pool. Run following commands to create directory for our pool statistic and script. Metric `adapools_pledged` is missing in cexplorer(a tool what will substitute adapools), so you might see relative data missing on dashboard from SNSKY, mentioned above.\n\n`adapools_pledged`\n`cd /$NODE_HOME  \n  \nmkdir -p poolStat  \n  \ncd poolStat  \n  \necho \"curl https://js.cexplorer.io/api-static/pool/< YOUR POOL BECH 32 POOL ID >.json 2>/dev/null \\\\  \n| jq '.data' | jq 'del(.stats, .url , .img, .updated, .handles, .pool_id, .name, .pool_id_hash)' \\\\  \n| tr -d \\\\\\\"{},: \\\\  \n| awk NF \\\\  \n| sed -e 's/^[ \\t]*/cexplorer_/' > poolStat.prom\" > getstats.sh  \n  \nchmod +x getstats.sh  \n  \n./getstats.sh`\n\ncheck the content of `poolStat.prom` and it should not contain only numeric values:\n\n`poolStat.prom`\n`$ nano poolStat.prom`\n\nConfigure `prometheus-node-exporter.service` to grab data from the `poolStat.prom` file:\n\n`prometheus-node-exporter.service`\n`poolStat.prom`\n`$ sudo cp /lib/systemd/system/prometheus-node-exporter.service /lib/systemd/system/prometheus-node-exporter.service_backup  \n  \n$ sudo nano /lib/systemd/system/prometheus-node-exporter.service`\n\nChange `ExecStart` line to:\n\n`ExecStart`\n`ExecStart=/usr/bin/prometheus-node-exporter --collector.textfile.directory=< YOUR NODE FULL PATH >/poolStat --collector.textfile`\n\nReload daemon and restart services:\n\n`$ sudo systemctl daemon-reload  \n  \n$ sudo systemctl restart prometheus-node-exporter.service  \n  \n$ sudo systemctl restart prometheus.service`\n\nNow you should see in the Dashboard all Cexplorer statistics\n\nSince the statistics will change, lets set cron job to update data from Cexplorer everyday\n\n`$ crontab -e`\n`##############################  \n  \n#Get data from Cexplorer every day at 06:00  \n  \n0 6 * * * <YOUR NODE FULL PATH >/poolStat/getstats.sh  \n  \n##############################`\n\nDone!\n\n## 6. Set up Grafana Alerting and Email Notifications[​](#6-set-up-grafana-alerting-and-email-notifications \"Direct link to 6. Set up Grafana Alerting and Email Notifications\")\n\nSet up SMTP in Grafana:\n\n`$ sudo nano /etc/grafana/grafana.ini`\n\nEdit the SMTP section:\n\n`#############################  \n  \n[smtp]  \nenabled = true  \nhost = smtp.<email server>:465  \nuser = <email user name>  \n# If the password contains # or ; you have to wrap it with triple quotes. Ex \"\"\"#password;\"\"\"  \npassword = <email password>  \nfrom_address = sam@sanskys.de  \nfrom_name = Grafana  \n  \n#############################`\n\nLog in to Grafana with username and password:\n\n![Email Alert](/assets/images/snsky_EmailAlert-7dff5020a2aadc8ac4af1264fa3118ae.jpg)\n\n![Email Alert](/assets/images/snsky_EmailAlert-7dff5020a2aadc8ac4af1264fa3118ae.jpg)\n\nClick on the \"Bell\" icon on the left sidebar.\n\nSelect \"Notification channels.\"\n\nClick on \"Add Channel.\" This will open a form for adding new notification channel.\n\nGive a name to this channel. I am using \"Alert\"\n\nSelect Email from \"Type\" as we want to send notifications over email.\n\nCheck the \"Send on all alerts\" in case you want email on all alerts.\n\nSelect the checkbox of \"Include image\" in case you want to include the image of the panel as the body in the notification email.\n\nAdd the target email in \"Email addresses\" text area. You can use multiple email address separated by \";\"\n\nClick on \"Send Test\" if you want to verify your settings. This will send a sample email using the SMTP details we configured earlier.\n\nClick on \"Save\" to add this channel\n\nCreate an Alert if Producer Node is not reachable\n\n![Peer Alert](/assets/images/snsky_PeerAlert-88ec86223b142e44ee49fa17fe71c336.jpg)\n\n![Peer Alert](/assets/images/snsky_PeerAlert-88ec86223b142e44ee49fa17fe71c336.jpg)\n\nPlease not that Alerts can only be created for \"Graph\" panels!\n\nNow we create an Alert to get an email if the Producer Node is not reachable\n\nIn the \"Connected Peers\" panel go to Alerts\n\nDefine the Rule \"Connected Peer Alert\" Evaluate every \"1m\" For \"2m\"\n\nCondition\n\n`WHEN \"last()\" OF \"query(A, 1m, now)\" \"HAS NO VALUE\"`\n\nNo Data & Error Handling\n\nIf no data or all values are null SET STATE TO \"No Data\"\n\nIf execution error or timeout SET STATE TO \"Alerting\"\n\nNotifications\n\nSend To - Choose your notification channel, which in my case is \"Alert\"\n\nMessage - type in your alert message that should appear in the email\n\nPress on \"test Rule\" to ensure that the Alert is correct and has no issues.\n\nNow you are done! Stop you Producer Node and you should get an Alert within 4min.\n\nIf everything works, now you should have a smile on your face! And if you wish to support the Tutorial work, you could donate or delegate to my pool - SNSKY\n\nDonation Address\n**addr1qyyhd8cpv4gmhr5axerhezhtzldrw4rp9ayf0fc6arnme4cg46du2qg366943uy0dw5yjmna7arfw265lu4r2fjccl4scf7xrw**\nSNSKY Pool ID\n**075578defd7ee97cbeaa2937e5819099cb3835ac9f9c8b1a2c3a3578**\n\n## 7. Recommended: Disabling Grafana Registrations and Anonymous Access[​](#7-recommended-disabling-grafana-registrations-and-anonymous-access \"Direct link to 7. Recommended: Disabling Grafana Registrations and Anonymous Access\")\n\nWe should make Grafana a bit more secure. To do so let's change two settings:\n\n`$ sudo nano /etc/grafana/grafana.ini`\n\nLocate the following `allow_sign_up` directive under the `[users]` heading and change the line as follows:\n\n`allow_sign_up`\n`[users]`\n`##########  \n  \n[users] # disable user signup / registration  \n  \nallow_sign_up = false  \n  \n##########`\n\nNext, locate the following enabled directive under the `[auth.anonymous]` heading and change the line as follows:\n\n`[auth.anonymous]`\n`[auth.anonymous]  \n  \nenabled = false`\n\nSave the file and exit your text editor. To activate the changes, restart Grafana.\n\n`$ sudo systemctl restart grafana-server`\n\n## 8. Advanced Users: Slot Leader Panel[​](#8-advanced-users-slot-leader-panel \"Direct link to 8. Advanced Users: Slot Leader Panel\")\n\n![Leader Panel](/assets/images/snsky_leaderPanel-ad1d395b4ef55b3e7ca790b1eb2fdaa5.jpg)\n\n![Leader Panel](/assets/images/snsky_leaderPanel-ad1d395b4ef55b3e7ca790b1eb2fdaa5.jpg)\n\nOnce your pool gets big and is regularly minting blocks, it becomes difficult to keep track of all Leader Slots and also to identify the available gaps for pool maintenance. This Slot Leader Panel is quite helpful as it gives a good overview of all scheduled Slots in TimeSeries.\n\nUse `cardano-cli` to query the leadership schedule. Since the result has to interpreted by Grafana, we need to format the query output to a CSV readable syntax.\n\n`cardano-cli`\n\nThe `cardano-cli` query requires additional RAM. Please refer to [query leadership-schedule](https://github.com/IntersectMBO/cardano-node/issues/3673) for more details. I needed 16GB RAM + 8GB SWAP and it took several minutes to query the leadership schedule.\n\n`cardano-cli`\n\nThe whole script can be copied from here:\n\n[Slot Leader Script](https://github.com/sanskys/SNSKY/blob/main/SlotLeader/script.sh)\n\nIn case the slot.csv file is on a different node, copy it to your Grafana Monitoring node manually. This step could be automated but I don't wish to open extra ports for this so I just copy and paste the content of the slot.csv file.\n\nNext, we add the CSV Plugin to Grafana. Please follow the instructions under the section \"Installing on a local Grafana:\"\n\n[Grafana CSV Plugin](https://grafana.com/grafana/plugins/marcusolsson-csv-datasource/?tab=installation)\n\nAfter the installation, in Data Sources now the CSV Plugin should be listed. Configure the CSV Plugin by specifying the location of the slot.csv file. Save & Test and if all steps were followed correctly, you should get the green success message.\n\nThe final step is to add the Slot Leader Panel to your dashboard. For that click on the \"Add Panel\" and \"Add New Panel\" icons.\n\nThen click on \"Query inspector\" and and \"JSON\" buttons.\n\nDelete the existing JSON code and replace it with the following:\n\n[Slot Leader Panel](https://github.com/sanskys/SNSKY/blob/main/SlotLeader/LeaderPanel.json)\n\nNow click on \"Apply\" and thats it! You should be able to see all your Leader Slots from last 6 Hrs to next 18 Hrs and this time window shifts automatically.\n\nHappy minting!\n\n## 9. Adding crypto exchange rates to your Grafana[​](#9-adding-crypto-exchange-rates-to-your-grafana \"Direct link to 9. Adding crypto exchange rates to your Grafana\")\n\nIt may not be healthy to look into price all day long, but it could be useful to have it in one place on the Grafana dashboard.\n\nBelow is an example using Kraken exchange's API for fetching prices. One may elect any alternate API provider for price and adapt the suggestions easily.\n\nBelow is the main snippet that will populate data to Prometheus (keeping in line with the folder structure used on this page). It is essential to ensure that `jq` and `curl` are already present on the system.\n\n`jq`\n`curl`\n\nLet's start by creating `$NODE_HOME/poolStat/prices.sh` with contents as per below:\n\n`$NODE_HOME/poolStat/prices.sh`\n`PRICES=$(curl -s https://api.kraken.com/0/public/Ticker?pair=ADAEUR,ADAUSD,XXBTZUSD,XETHZUSD)  \necho $PRICES | jq .result.ADAEUR.c | jq .[0] | sed 's/\"//g'| sed 's/^/adaeur /' > $NODE_HOME/poolStat/price.prom  \necho $PRICES | jq .result.ADAUSD.c | jq .[0] | sed 's/\"//g'| sed 's/^/adausd /' >> $NODE_HOME/poolStat/price.prom  \necho $PRICES | jq .result.XXBTZUSD.c | jq .[0] | sed 's/\"//g'| sed 's/^/btcusd /' >> $NODE_HOME/poolStat/price.prom  \necho $PRICES | jq .result.XETHZUSD.c | jq .[0] | sed 's/\"//g'| sed 's/^/ethusd /' >> $NODE_HOME/poolStat/price.prom`\n\nAs you can see it is very simple script with self explanatory code and if you need any other currency to be added first just check out `curl -s https://api.kraken.com/0/public/AssetPairs` as it should return all available asset pairs and add your needed pair in the bottom with respective code(what should be quite easy to do).\n\n`curl -s https://api.kraken.com/0/public/AssetPairs`\n\nNow you need to make this script executable:\n\n`chmod +x $NODE_HOME/poolStat/prices.sh`\n\nRun `$NODE_HOME/poolStat/prices.sh` at shell and ensure that you see file `$NODE_HOME/poolStat/price.prom` with content similar to below:\n\n`$NODE_HOME/poolStat/prices.sh`\n`$NODE_HOME/poolStat/price.prom`\n`adaeur 0.502300  \nadausd 0.531625  \nbtcusd 30187.90000  \nethusd 2012.02000`\n\nThen you should go to your Grafana and check explore and then metrics browser menu and there you should able to see `adaeur`, `adausd` and other metrics what we write to file.\n\n`adaeur`\n`adausd`\n\nIf metrics are there, then you must configure cron to run that script every minute, so you will get fresh data every minute:\n\n`crontab -l 2>/dev/null; echo \"* * * * * $NODE_HOME/poolStat/prices.sh\") | crontab -`\n\nNow all is left is to create a graph with prices: it is a rather trivial task and no explanation is necessary.\n\nCheers!",
  "images": [],
  "extraction_metadata": {
    "batch_number": 9,
    "extraction_timestamp": "2025-09-19T14:05:00.496633",
    "extraction_time": 2.430634021759033,
    "source": "tavily_api_raw"
  }
}