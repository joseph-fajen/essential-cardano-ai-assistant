{
  "url": "https://docs.cardano.org/about-cardano/explore-more/cardano-network/networking-protocol",
  "content": "Opens in a new window Opens an external website Opens an external website in a new window\n\nThis website utilizes technologies such as cookies to enable essential site functionality, as well as for analytics, personalization, and targeted advertising. To learn more, view the following link:    [Privacy Policy](https://static.iohk.io/terms/iog-privacy-policy.pdf)[Cookie Policy](https://static.iohk.io/terms/iog-cookie-policy.pdf)\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)\n\n# Networking protocol design overview\n\nTransmission Control Protocols (TCP) and Internet Protocols (IP) form a protocol\nsuite universally deployed on the network. TCP/IP enables a reliable\nbidirectional communication channel between systems on the internet.\n\nThe ordered delivery of *Cardano node communication protocols* is guaranteed by\nthe TCP/IP protocol.\n\nOperating systems limit the number of concurrent connections. By default, Linux,\nfor example, can open 1,024 connections per process, whereas macOS limits this\nnumber to 256. To avoid excessive use of resources and enable reliable means for\nconnection establishment, Cardano uses a *multiplexer*.\n\n## Connection management[​](#connection-management \"Direct link to Connection management\")\n\nThe network layer handles a range of specific tasks besides the exchange of\nblock and transaction information required by the Ouroboros protocol.\n\nGenerally, connection management implementation includes the performance of the\nfollowing tasks:\n\n* opening a socket and/or acquiring resources from the OS\n* negotiating the protocol version with the handshake mini-protocol\n* spawning the thread that runs the multiplexer (which can be instructed to\n  start/stop various mini-protocols)\n* discovering and classifying exceptions thrown by mini-protocols or the\n  multiplexer itself\n* shutting down the connection in case of an error\n* handling a shutdown request from the peer\n* shutting down the threads that run mini-protocols\n* closing a socket.\n\n## Multiplexing[​](#multiplexing \"Direct link to Multiplexing\")\n\nThe multiplexing layer acts as a central crossing between mini-protocols and the\nnetwork channel. It runs several\n[mini-protocols](/about-cardano/explore-more/cardano-network#utilizing-mini-protocols)\nin parallel in a single channel ‒ TCP connection, for example.\n\nFigure 1 reflects how data flows between two nodes, each running three\nmini-protocols using a multiplexer (MUX) and a de-multiplexer (DEMUX).\n\nFigure 1. Data flow between the nodes through multiplexing\n\nData transmitted between nodes passes through the MUX/DEMUX of the nodes. There\nis a fixed pairing of mini-protocol instances, which means that each instance\nonly communicates with its dual instance (an initiator and a responder side).\n\nThe implementation of the mini-protocol also handles serialization and\nde-serialization of its messages. Mini-protocols write chunks of bytes to the\nMUX and read chunks of bytes from the DEMUX. The MUX reads the data from\nmini-protocols, splits it into segments, adds a segment header, and transmits\nthe segments to the DEMUX of its peer. The DEMUX uses the segment’s headers to\nreassemble byte streams for the mini-protocols on its side. The multiplexing\nprotocol (see the note below) itself is completely agnostic to the structure of\nthe multiplexed data.\n\nnote\n\nThis is not a generic, but specialized, use of multiplexing. Individual\nmini-protocols have strict constraints on unacknowledged messages that can be in\nflight. The design avoids the conditions in which the use of general TCP over\nTCP multiplexing creates chaotic performance.\n\n## Data segments of the multiplexing protocol[​](#data-segments-of-the-multiplexing-protocol \"Direct link to Data segments of the multiplexing protocol\")\n\nMultiplexing data segments include the following details:\n\n* **Transmission time** ‒ a timestamp based on the lower 32 bits of the sender’s\n  monotonic clock with a resolution of one microsecond\n* **Mini-protocol ID** ‒ the unique ID of the mini-protocol\n* **Payload length** ‒ the size of the segment payload in bytes; the maximum\n  payload length supported by the multiplexing wire format is 216 − 1. Note that\n  an instance of the protocol can choose a smaller limit for the size of\n  segments it transmits\n* **Mode** ‒ the single bit M (the mode) is used to distinguish the dual\n  instances of a mini-protocol. The mode is set to 0 in segments from the\n  initiator (the side that initially has agency), and it is set to 1 in segments\n  from the responder.\n\n## Cardano node communication protocols[​](#cardano-node-communication-protocols \"Direct link to Cardano node communication protocols\")\n\nCardano uses inter-process communication (IPC) protocols to allow for the\nexchange of blocks and transactions between nodes, and to allow local\napplications to interact with the blockchain via the node.\n\n### Node-to-node IPC overview[​](#node-to-node-ipc-overview \"Direct link to Node-to-node IPC overview\")\n\nThe Node-to-node (NtN) protocol transfers transactions between full nodes. NtN\nincludes three mini-protocols (chain-sync, block-fetch, and tx-submission),\nwhich are multiplexed over a single TCP channel using a network-mux package.\n\nThe following diagram represents the NtN operational flow:\n\nNtN follows a pull-based strategy, where the initiator node queries for new\ntransactions and the responder node replies with the transactions if any exist.\nThis protocol perfectly suits a trustless setting where both sides need to be\nprotected against resource consumption attacks from the other side.\n\n**NtN mini-protocols explained**\n\nA brief explanation of the NtN mini-protocols:\n\n* **chain-sync**: a protocol that allows a node to reconstruct a chain of an\n  upstream node\n* **block-fetch**: a protocol that allows a node to download block bodies from\n  various peers\n* **tx-submission**: a protocol that allows submission of transactions. The\n  implementation of this protocol is based on a generic mini protocol framework,\n  with one peculiarity: the roles of the initiator and the responder are\n  reversed. The Server is the initiator that asks for new transactions, and the\n  Client is the responder that replies with the transactions. This role reversal\n  was designed thus for technical reasons.\n\nTo ensure optimal networking service, the team has also implemented an\nadditional protocol:\n\n* **keep-alive**: a protocol that ensures continuous connection between nodes\n  and minimizes performance faults.\n\n### Node-to-client IPC overview[​](#node-to-client-ipc-overview \"Direct link to Node-to-client IPC overview\")\n\nNode-to-client (NtC) is a connection between a full node and a client that\nconsumes data but does not take part in the Ouroboros protocol (a wallet, for\nexample.)\n\nThe purpose of the NtC IPC protocol is to allow local applications to interact\nwith the blockchain via the node. This includes applications such as wallet\nbackends or blockchain explorers. The NtC protocol enables these applications to\naccess the raw chain data and to query the current ledger state, and it also\nprovides the ability to submit new transactions to the system.\n\nThe NtC protocol uses the same design as the node-to-node (NtN) protocol, but\nwith a different set of mini-protocols, and using local pipes rather than TCP\nconnections. As such, it is a relatively low-level and narrow interface that\nexposes only what the node can provide natively. For example, the node provides\naccess to all the raw chain data but does not provide a way to query data on the\nchain. The job of providing data services and more convenient higher-level APIs\nis delegated to dedicated clients, such as cardano-db-sync and the wallet\nbackend.\n\n**NtC mini-protocols**\n\nThe NtC protocol consists of three mini-protocols:\n\n* **chain-sync** - used for following the chain and getting blocks\n* **local-tx-submission** - used for submitting transactions\n* **local-state-query** - used for querying the ledger state.\n\nThe NtC version of chain-sync uses full blocks, rather than just block headers.\nThis is why no separate block-fetch protocol is needed. The local-tx-submission\nprotocol is like the NtN tx-submission protocol but simpler, and it returns the\ndetails of transaction validation failures. The local-state-query protocol\nprovides query access to the current ledger state, which contains a lot of\ninteresting data that is not directly reflected on the chain itself.\n\n**How NtC works**\n\nIn NtC, the node runs the producer side of the chain-sync protocol only, and the\nclient runs the consumer side only.\n\nThis table shows which mini-protocols are enabled for NtC communication:\n\nOn this page\n\n* [Connection management](#connection-management)\n* [Multiplexing](#multiplexing)\n* [Data segments of the multiplexing protocol](#data-segments-of-the-multiplexing-protocol)\n* [Cardano node communication protocols](#cardano-node-communication-protocols)\n  + [Node-to-node IPC overview](#node-to-node-ipc-overview)\n  + [Node-to-client IPC overview](#node-to-client-ipc-overview)",
  "images": [],
  "extraction_metadata": {
    "batch_number": 1,
    "extraction_timestamp": "2025-09-29T13:36:02.262771",
    "extraction_time": 1.9533109664916992,
    "source": "tavily_api_raw"
  }
}